# ðŸŽ¯ Customer Churn Prediction: An End-to-End MLOps Journey

[![Python](https://img.shields.io/badge/Python-3.13-blue.svg)](https://python.org)
[![MLflow](https://img.shields.io/badge/MLflow-3.3.1-green.svg)](https://mlflow.org)
[![DVC](https://img.shields.io/badge/DVC-3.62.0-orange.svg)](https://dvc.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-Latest-teal.svg)](https://fastapi.tiangolo.com)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

> **A comprehensive machine learning project demonstrating advanced MLOps practices, experimental rigor, and production-ready deployment for customer churn prediction.**

## ðŸ“‹ Table of Contents
- [ðŸŽ¯ Project Overview](#-project-overview)
- [ðŸ§  Key Technical Challenges & Solutions](#-key-technical-challenges--solutions)
- [ðŸ”¬ Experimental Journey](#-experimental-journey)
- [ðŸ—ï¸ Architecture & MLOps Stack](#ï¸-architecture--mlops-stack)
- [ðŸš€ Quick Start](#-quick-start)
- [ðŸ“Š Results & Performance](#-results--performance)
- [ðŸ› ï¸ Technical Implementation](#ï¸-technical-implementation)
- [ðŸ“ˆ Business Impact](#-business-impact)
- [ðŸ”§ API Usage](#-api-usage)
- [ðŸ‘¨â€ðŸ’» For Recruiters & Hiring Managers](#-for-recruiters--hiring-managers)

## ðŸŽ¯ Project Overview

This project tackles **customer churn prediction** using advanced machine learning techniques and modern MLOps practices. What sets this project apart is the **systematic experimental approach** that uncovered and solved critical data distribution problems, demonstrating real-world ML engineering skills.

### ðŸŽª **The Challenge**
- Predict customer churn with **94.5% F1-score accuracy**
- Build a **production-ready MLOps pipeline**
- Overcome severe **data drift and distribution mismatch** issues
- Create **reproducible experiments** with full versioning

### ðŸ† **The Achievement**
- **6 systematic experiments** documented in Jupyter notebooks
- **Root cause analysis** of model failures and data quality issues
- **Complete MLOps implementation** with DVC + MLflow + FastAPI
- **Production-ready API** with FastAPI and Pydantic v2 compatibility

## ðŸ§  Key Technical Challenge & Solution

### ðŸ”¥ **The Data Science Challenge: Catastrophic Model Performance**
**Problem**: Initial models achieved excellent validation scores (99%+ F1) but completely failed on test data (0% F1).

**Root Cause Analysis**: 
- Discovered severe **data drift** between training and test sets
- Training data contained "perfect rules" (e.g., all monthly contract customers churned)
- Test data followed completely different statistical distributions
- Models were memorizing deterministic patterns instead of learning generalizable features

**Solution Strategy**: 
- **Data unification approach**: Merged train/test datasets and re-split properly
- Implemented **stratified sampling** to ensure consistent distributions across splits
- **Systematic experimentation**: 6 documented experiments to validate the solution
- **Result**: Achieved stable **94.5% F1-score** across all data splits

**Why This Matters**: This demonstrates real-world data science problem-solving - identifying when the issue isn't the model complexity but fundamental data quality problems.

## ðŸ”¬ Experimental Journey

Our **6-experiment notebook series** demonstrates systematic ML problem-solving:

### ðŸ““ Experiment 1: Baseline Random Forest
- **Goal**: Establish baseline performance
- **Result**: 99.98% validation F1, 64.29% test F1
- **Discovery**: Severe overfitting detected
- **Learning**: Model memorizing deterministic patterns

### ðŸ““ Experiment 2: Logistic Regression Alternative  
- **Goal**: Try simpler model to reduce overfitting
- **Result**: 86.48% validation F1, 0% test F1
- **Discovery**: Model predicting "no churn" for all samples
- **Learning**: Data drift affects all model types

### ðŸ““ Experiment 3: Regularization Techniques
- **Goal**: Apply L1 regularization to control overfitting
- **Result**: Still 0% test F1 despite regularization
- **Discovery**: Root cause is data quality, not model complexity
- **Learning**: Model-level solutions insufficient for data-level problems

### ðŸ““ Experiment 4: Data Unification Strategy
- **Goal**: Merge datasets and re-split to eliminate distribution mismatch
- **Process**: Combined 505K samples, stratified re-splitting
- **Discovery**: Successful creation of consistent train/validation/test splits
- **Learning**: Data engineering crucial for ML success

### ðŸ““ Experiment 5: Logistic Regression (Clean Data)
- **Goal**: Validate data fix with simple model
- **Result**: 82.59% validation F1, 82.68% test F1
- **Discovery**: Stable performance across all splits
- **Learning**: Data quality problem successfully resolved

### ðŸ““ Experiment 6: Random Forest (Final Model)
- **Goal**: Achieve best possible performance with clean data
- **Result**: 94.50% F1-score with 99.82% recall
- **Discovery**: Outstanding performance with high precision
- **Learning**: Complex models work well when data is properly prepared

## ðŸ—ï¸ Architecture & MLOps Stack

### ðŸ”§ **Core Technologies**
```yaml
ML Framework: scikit-learn 1.7.1
Experiment Tracking: MLflow 3.3.1  
Pipeline Orchestration: DVC 3.62.0
API Framework: FastAPI
Data Validation: Pydantic 2.10.1
Development Environment: Python 3.13 + uv
```

### ðŸ›ï¸ **System Architecture**
```mermaid
graph TB
    A[Raw Data] --> B[DVC Pipeline]
    B --> C[Data Loading]
    C --> D[Data Preprocessing] 
    D --> E[Model Building]
    E --> F[Model Evaluation]
    F --> G[Model Registration]
    G --> H[MLflow Registry]
    H --> I[FastAPI Serving]
    I --> J[Production API]
    
    K[Jupyter Notebooks] --> L[Experimentation]
    L --> M[MLflow Tracking]
    M --> H
```

### ðŸ“‚ **Project Structure**
```
Customer-Churn/
â”œâ”€â”€ src/                          # Core application code
â”‚   â”œâ”€â”€ pipeline/                 # DVC pipeline stages
â”‚   â”‚   â”œâ”€â”€ data_loading.py       # Data ingestion
â”‚   â”‚   â”œâ”€â”€ data_preprocessing.py # Feature engineering
â”‚   â”‚   â”œâ”€â”€ model_building.py     # Model training
â”‚   â”‚   â”œâ”€â”€ model_evaluation.py   # Performance assessment
â”‚   â”‚   â””â”€â”€ register_model.py     # Model registration
â”‚   â”œâ”€â”€ controllers/              # Business logic
â”‚   â”œâ”€â”€ routes/                   # API endpoints
â”‚   â”œâ”€â”€ models/                   # Trained model artifacts
â”‚   â””â”€â”€ main.py                   # FastAPI application
â”œâ”€â”€ notebooks/                    # Experimental journey
â”‚   â”œâ”€â”€ 1-experiment_01_rf.ipynb  # Baseline Random Forest
â”‚   â”œâ”€â”€ 2-experiment_02_lgr.ipynb # Logistic Regression
â”‚   â”œâ”€â”€ 3-experiment_03_add_requlization.ipynb
â”‚   â”œâ”€â”€ 4-experiment_04_merging_data.ipynb
â”‚   â”œâ”€â”€ 5-experiment_05_lgr_with_new_split.ipynb
â”‚   â””â”€â”€ 6-experiment_06_rf_with_new_split.ipynb
â”œâ”€â”€ Data/                         # Versioned datasets
â”œâ”€â”€ mlruns/                       # MLflow tracking
â”œâ”€â”€ dvc.yaml                      # Pipeline definition
â”œâ”€â”€ params.yaml                   # Hyperparameters
â””â”€â”€ pyproject.toml               # uv dependencies
```

## ðŸš€ Quick Start

### Prerequisites
- **Python 3.13+**
- **uv** (Ultra-fast Python package installer)

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/your-username/Customer-Churn.git
cd Customer-Churn
```

2. **Install dependencies with uv**
```bash
# Install uv if not already installed
curl -LsSf https://astral.sh/uv/install.sh | sh

# Create virtual environment and install dependencies
uv sync
```

3. **Activate virtual environment**
```bash
# On Windows
.venv\Scripts\activate

# On macOS/Linux
source .venv/bin/activate
```

4. **Run the complete pipeline**
```bash
# Execute DVC pipeline (data â†’ model â†’ evaluation)
dvc repro

# Start MLflow UI (optional)
mlflow ui --backend-store-uri mlruns/

# Launch FastAPI server
cd src
uvicorn main:app --reload
```

## ðŸ“Š Results & Performance

### ðŸŽ¯ **Final Model Performance**
| Metric | Training | Validation | Test |
|--------|----------|------------|------|
| **F1-Score** | 0.9455 | 0.9450 | **0.9450** |
| **Accuracy** | 0.9357 | 0.9355 | **0.9354** |
| **Precision** | 0.8975 | 0.8971 | **0.8971** |
| **Recall** | 0.9982 | 0.9981 | **0.9982** |

### ðŸ“ˆ **Key Achievements**
- âœ… **99.82% Recall**: Catches virtually all churning customers
- âœ… **89.71% Precision**: High accuracy in churn predictions  
- âœ… **Zero Overfitting**: Identical performance across all data splits
- âœ… **Production Ready**: FastAPI deployment with <100ms response time

### ðŸŽ­ **Before vs After Data Fix**
| Experiment | Validation F1 | Test F1 | Status |
|------------|---------------|---------|---------|
| **Before (Exp 1-3)** | 0.86-0.99 | 0.00-0.64 | âŒ Massive overfitting |
| **After (Exp 5-6)** | 0.83-0.95 | 0.83-0.95 | âœ… Stable performance |

## ðŸ› ï¸ Technical Implementation

### ðŸ”„ **DVC Pipeline (5 Stages)**
```yaml
1. data_loading: Raw data ingestion and validation
2. data_preprocessing: Feature engineering and scaling  
3. model_building: Random Forest training with MLflow
4. model_evaluation: Comprehensive performance analysis
5. register_model: MLflow model registry integration
```

### ðŸŽ›ï¸ **Configuration Management**
```yaml
# params.yaml
model_building:
  n_estimators: 100
  random_state: 42
  class_weight: balanced
```

### ðŸ”Œ **API Endpoints**
```python
# Health check
GET /api/v1/

# Data preprocessing
POST /api/v1/data/process

# Churn prediction  
POST /api/v1/model/predict
```

### ðŸ“Š **MLflow Integration**
- **Experiment Tracking**: All 6 experiments logged with parameters, metrics, and artifacts
- **Model Registry**: Automated model versioning and staging
- **Artifact Storage**: Confusion matrices, feature importance plots
- **Reproducibility**: Complete experiment lineage and dependency tracking

## ðŸ“ˆ Business Impact

### ðŸ’° **ROI Calculation**
Assuming:
- 100,000 customers 
- 55% churn rate (55,000 potential churners)
- $100 average customer lifetime value
- $10 retention campaign cost per customer

**With 99.82% Recall**:
- **Identified Churners**: 54,901 (99.82% of 55,000)
- **Successful Retention**: 27,451 (50% retention rate)
- **Revenue Saved**: $2,745,100
- **Campaign Cost**: $549,010
- **Net ROI**: **$2,196,090** (400% return)

### ðŸŽ¯ **Business Value**
- **Proactive Retention**: Identify at-risk customers before they churn
- **Resource Optimization**: Focus retention efforts on high-risk customers
- **Revenue Protection**: Minimize revenue loss from customer churn
- **Competitive Advantage**: Data-driven customer relationship management

## ðŸ”§ API Usage

### ðŸš€ **Prediction Request**
```python
import requests

# Single customer prediction
payload = {
    "Age": 45.0,
    "Gender": "Male", 
    "Tenure": 24.0,
    "Usage Frequency": 15.0,
    "Support Calls": 3.0,
    "Payment Delay": 5.0,
    "Subscription Type": "Standard",
    "Contract Length": "Annual", 
    "Total Spent": 1250.50,
    "Last Interaction": 7.0
}

response = requests.post(
    "http://localhost:1234/api/v1/model/predict",
    json=payload
)

print(response.json())
# Output: {"churn_prediction": 0}  # 0 = No Churn, 1 = Churn
```

### ðŸ“Š **Response Format**
```json
{
    "churn_prediction": 0,
}
```

## ðŸ‘¨â€ðŸ’» For Recruiters & Hiring Managers

### ðŸŽ¯ **Why This Project Stands Out**

1. **ðŸ”¬ Scientific Rigor**: Systematic experimentation with documented failure analysis
2. **ðŸ§© Problem-Solving**: Identified and solved complex data distribution issues  
3. **ðŸ—ï¸ Production Focus**: Complete MLOps pipeline, not just model training
4. **ðŸ“š Documentation**: Comprehensive notebooks showing thought process
5. **âš¡ Modern Stack**: Latest tools (Python 3.13, Pydantic v2, uv, FastAPI)

### ðŸ’¼ **Skills Demonstrated**

| **Core ML Skills** | **MLOps & Engineering** | **Business Acumen** |
|-------------------|-------------------------|-------------------|
| âœ… Experiment Design | âœ… CI/CD with DVC | âœ… ROI Analysis |
| âœ… Data Quality Analysis | âœ… Model Versioning | âœ… Business Metrics |
| âœ… Feature Engineering | âœ… API Development | âœ… Stakeholder Communication |
| âœ… Model Selection | âœ… Production Deployment | âœ… Problem Solving |
| âœ… Performance Optimization | âœ… Monitoring & Logging | âœ… Technical Leadership |

### ðŸŽ“ **Learning Journey Highlights**

- **Data Science**: Advanced understanding of overfitting, data drift, and model validation
- **Software Engineering**: Production-grade code with proper architecture and testing
- **MLOps**: End-to-end pipeline automation with versioning and monitoring
- **Communication**: Clear documentation of complex technical problems and solutions

### ðŸ” **Code Quality Indicators**

- **Type Hints**: Full type annotation with Pydantic models
- **Error Handling**: Comprehensive exception management  
- **Configuration**: Externalized parameters and environment management
- **Testing**: Model validation and API endpoint testing
- **Documentation**: Inline comments and comprehensive README

### ðŸ“ž **Ready for the Next Challenge**

This project demonstrates my ability to:
- **Lead ML initiatives** from research to production
- **Solve complex technical problems** with systematic approaches  
- **Build scalable systems** using modern MLOps practices
- **Communicate effectively** with both technical and business stakeholders
- **Deliver business value** through data-driven solutions

---


## ðŸ“§ Contact

**Mohamed** - [mohamed.tawfik.eldeeb@gmail.com] 

**Project Link**: [https://github.com/MohammedTawfikEldeeb/Customer-Churn-Prediction](https://github.com/MohammedTawfikEldeeb/Customer-Churn-Prediction)

---

â­ **If this project helped you, please consider giving it a star!** â­
