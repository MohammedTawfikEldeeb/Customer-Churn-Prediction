{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06b9c987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f016032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "processed_dir = os.path.join(project_root, \"notebooks\", \"data\")\n",
    "\n",
    "X_train = pd.read_csv(os.path.join(processed_dir, \"X_train_scaled.csv\"))\n",
    "y_train = pd.read_csv(os.path.join(processed_dir, \"y_train.csv\"))\n",
    "\n",
    "X_valid = pd.read_csv(os.path.join(processed_dir, \"X_valid_scaled.csv\"))\n",
    "y_valid = pd.read_csv(os.path.join(processed_dir, \"y_valid.csv\"))\n",
    "\n",
    "df_test = pd.read_csv(os.path.join(processed_dir, \"test_preprocessed.csv\"))\n",
    "\n",
    "X_test = df_test.drop(columns=[\"Churn\"])\n",
    "y_test = df_test[\"Churn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "818e9e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Run: L1 Regularized Logistic Regression ---\n",
      "Training Logistic Regression...\n",
      "Validation F1-Score (LGR): 0.8647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Mohamed\\Work\\Customer-Churn\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "2025/08/26 09:26:45 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1-Score (LGR): 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 09:26:58 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 09:26:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Run Finished ---\n",
      "üèÉ View run L1_Regularized_Logistic_Regression at: http://127.0.0.1:5000/#/experiments/849762709934598647/runs/bea21584cfed4f8b88def77574a5726e\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/849762709934598647\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"Customer Churn Classification\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"L1_Regularized_Logistic_Regression\") as run:\n",
    "    print(\"\\n--- Starting Run: L1 Regularized Logistic Regression ---\")\n",
    "    \n",
    "    # --- a. Define Model and Parameters ---\n",
    "    lgr_params = {\n",
    "        'penalty': 'l1',\n",
    "        'C': 0.1,  # Strong regularization\n",
    "        'solver': 'liblinear',\n",
    "        'class_weight': 'balanced',\n",
    "        'random_state': 42\n",
    "    }\n",
    "    lgr = LogisticRegression(**lgr_params)\n",
    "    \n",
    "    mlflow.log_params(lgr_params)\n",
    "\n",
    "    # --- b. Train and Evaluate ---\n",
    "    print(\"Training Logistic Regression...\")\n",
    "    lgr.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "    # Evaluate on Validation Set\n",
    "    y_pred_valid_lgr = lgr.predict(X_valid)\n",
    "    valid_f1_lgr = f1_score(y_valid, y_pred_valid_lgr)\n",
    "    mlflow.log_metric(\"validation_f1_score\", valid_f1_lgr)\n",
    "    print(f\"Validation F1-Score (LGR): {valid_f1_lgr:.4f}\")\n",
    "\n",
    "    # Evaluate on Test Set\n",
    "    y_pred_test_lgr = lgr.predict(X_test)\n",
    "    test_f1_lgr = f1_score(y_test, y_pred_test_lgr)\n",
    "    test_accuracy_lgr = accuracy_score(y_test, y_pred_test_lgr)\n",
    "    test_precision_lgr = precision_score(y_test, y_pred_test_lgr)\n",
    "    test_recall_lgr = recall_score(y_test, y_pred_test_lgr)\n",
    "    \n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy_lgr)\n",
    "    mlflow.log_metric(\"test_precision\", test_precision_lgr)\n",
    "    mlflow.log_metric(\"test_recall\", test_recall_lgr)\n",
    "    mlflow.log_metric(\"test_f1_score\", test_f1_lgr)\n",
    "    print(f\"Test F1-Score (LGR): {test_f1_lgr:.4f}\")\n",
    "\n",
    "    # --- c. Log Artifacts and Model ---\n",
    "    mlflow.sklearn.log_model(lgr, \"logistic_regression_model\")\n",
    "    print(\"--- Run Finished ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8034e2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Run: Regularized Random Forest ---\n",
      "Training Random Forest...\n",
      "Validation F1-Score (RF): 0.9775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 09:29:27 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1-Score (RF): 0.6429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/26 09:29:31 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/08/26 09:29:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Run Finished ---\n",
      "üèÉ View run Regularized_Random_Forest at: http://127.0.0.1:5000/#/experiments/849762709934598647/runs/5a3ec930ca4e49f886eb8f84807b0f5c\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/849762709934598647\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"Customer Churn Classification\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"Regularized_Random_Forest\") as run:\n",
    "    print(\"\\n--- Starting Run: Regularized Random Forest ---\")\n",
    "    \n",
    "    # --- a. Define Model and Parameters ---\n",
    "    rf_params = {\n",
    "        'n_estimators': 100,\n",
    "        'max_depth': 7,          # Control tree depth to prevent overfitting\n",
    "        'min_samples_leaf': 20,  # Ensure leaves are not too specific\n",
    "        'class_weight': 'balanced',\n",
    "        'random_state': 42\n",
    "    }\n",
    "    rf = RandomForestClassifier(**rf_params)\n",
    "    \n",
    "    mlflow.log_params(rf_params)\n",
    "\n",
    "    # --- b. Train and Evaluate ---\n",
    "    print(\"Training Random Forest...\")\n",
    "    rf.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "    # Evaluate on Validation Set\n",
    "    y_pred_valid_rf = rf.predict(X_valid)\n",
    "    valid_f1_rf = f1_score(y_valid, y_pred_valid_rf)\n",
    "    mlflow.log_metric(\"validation_f1_score\", valid_f1_rf)\n",
    "    print(f\"Validation F1-Score (RF): {valid_f1_rf:.4f}\")\n",
    "\n",
    "    # Evaluate on Test Set\n",
    "    y_pred_test_rf = rf.predict(X_test)\n",
    "    test_f1_rf = f1_score(y_test, y_pred_test_rf)\n",
    "    test_accuracy_rf = accuracy_score(y_test, y_pred_test_rf)\n",
    "    test_precision_rf = precision_score(y_test, y_pred_test_rf)\n",
    "    test_recall_rf = recall_score(y_test, y_pred_test_rf)\n",
    "    \n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy_rf)\n",
    "    mlflow.log_metric(\"test_precision\", test_precision_rf)\n",
    "    mlflow.log_metric(\"test_recall\", test_recall_rf)\n",
    "    mlflow.log_metric(\"test_f1_score\", test_f1_rf)\n",
    "    print(f\"Test F1-Score (RF): {test_f1_rf:.4f}\")\n",
    "\n",
    "    # --- c. Log Artifacts and Model ---\n",
    "    mlflow.sklearn.log_model(rf, \"random_forest_model\")\n",
    "    print(\"--- Run Finished ---\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aed32ff",
   "metadata": {},
   "source": [
    "After exhausting all possible model-level solutions:  \n",
    "- Complex model (Random Forest)  \n",
    "- Simple model (Logistic Regression)  \n",
    "- Regularization to penalize overfitting  \n",
    "\n",
    "‚Ä¶all of them **failed on the test data**.  \n",
    "The inevitable conclusion: the issue lies **entirely in the data**.\n",
    "\n",
    "There is a **complete mismatch** between the statistical distribution of the training and test sets.  \n",
    "The model learns the rules of one game, but is then asked to play an entirely different game with different rules. Under such conditions, no model can succeed.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Proposed Final Solution: Data Unification & Re-Splitting\n",
    "Since the root problem is in the data, the solution must also come from the data.  \n",
    "The logical next step is to create a consistent and homogeneous training‚Äìtesting environment.\n",
    "\n",
    "**Plan:**  \n",
    "1. **Merge the data**: Combine the original training and test files into one dataset.  \n",
    "2. **Full shuffle**: Randomly shuffle the unified dataset to eliminate any order or bias.  \n",
    "3. **Re-split**: Divide the shuffled dataset again into training, validation, and test sets with proper ratios.  \n",
    "\n",
    "This process ensures that the model is both trained and tested on data from the **same statistical source**, creating a realistic and valid scenario for learning and success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a56c97e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
